{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf27f083",
   "metadata": {},
   "source": [
    "# Demo: Run inference and compute metrics\n",
    "\n",
    "This notebook demonstrates how to: \n",
    "1. Download the required model checkpoints (encoder + decoder).\n",
    "2. Provide a sample or your own dataset (Google Drive zip or local directory) in the format expected by `src.datasets.custom_dir`.\n",
    "3. Run `inference.py` to produce predictions.\n",
    "4. Run `evaluator.py` (metrics script) to compute WER/CER.\n",
    "\n",
    "Notes: the repository already contains `inference.py` and `evaluator.py`. The evaluator script in this repo is `evaluator.py` (used instead of a `calc_metrics.py` name). Cells below include short explanations and runnable Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85927d",
   "metadata": {},
   "source": [
    "## 1) Install dependencies\n",
    "Run once to install packages from `requirements.txt`. In a Jupyter environment `!` works to call shell commands. If you already installed project dependencies (for example in a venv), you can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8aa905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements (uncomment if needed).\n",
    "# Note: in some environments you may want to run this in your terminal instead of the notebook.\n",
    "# !python -m pip install -r requirements.txt\n",
    "print('If needed, run: python -m pip install -r requirements.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862133c5",
   "metadata": {},
   "source": [
    "## 2) Download model checkpoints\n",
    "The repo's `Inferencer` will also download checkpoints automatically if needed, but this cell shows how to download them explicitly and save them under `checkpoints/`.\n",
    "We use the same Google Drive links referenced in `src/trainer/inferencer.py` and `src/configs/baseline.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gdown\n",
    "\n",
    "CHECKPOINTS_DIR = Path('checkpoints')\n",
    "CHECKPOINTS_DIR.mkdir(exist_ok=True)\n",
    "links = {\n",
    "    'encoder.pth': 'https://drive.google.com/uc?export=download&id=1UpX3_UgrbRTWYunAMHPsR09a1_zHzj7E',\n",
    "    'decoder.pth': 'https://drive.google.com/uc?export=download&id=1A1Cb1TCn5LWYuIADkOsfvzlBBBi2L2bi',\n",
    "}\n",
    "for name, url in links.items():\n",
    "    out_path = CHECKPOINTS_DIR / name\n",
    "    if out_path.exists():\n",
    "        print(f'{out_path} already exists, skipping download')\n",
    "        continue\n",
    "    print(f'Downloading {name} to {out_path} ...')\n",
    "    try:\n",
    "        gdown.download(url, str(out_path), quiet=False)\n",
    "    except Exception as e:\n",
    "        print('Download failed:', e)\n",
    "\n",
    "print('Done. Checkpoints saved to', CHECKPOINTS_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13987c41",
   "metadata": {},
   "source": [
    "## 3) Provide a dataset to run inference on\n",
    "You have two options:\n",
    "- Use the built-in HF Librispeech streaming dataset (configured in `src/configs/inference.yaml`).\n",
    "- Provide your own dataset as a ZIP hosted on Google Drive (recommended format below).\n",
    "\n",
    "If providing your own dataset, the ZIP should extract into a folder that contains `audio/` (wav/mp3/etc) and `transcriptions/` (matching .txt files for each audio file). The notebook will extract the archive into `data/datasets/custom_dir/` so `CustomDirDataset` can find it automatically.\n",
    "Example structure after extraction:\n",
    "data/datasets/custom_dir/audio/utt1.wav\n",
    "data/datasets/custom_dir/transcriptions/utt1.txt\n",
    "\n",
    "Below is a helper cell that will ask for a Google Drive file URL (or file id). It will download and extract the ZIP into `data/datasets/custom_dir/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import gdown\n",
    "\n",
    "def download_and_unzip_gdrive(link_or_id, target_dir=Path('data/datasets/custom_dir')):\n",
    "    target_dir = Path(target_dir)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Try to extract file id from several common Google Drive URL formats\n",
    "    m = re.search(r'id=([A-Za-z0-9_-]+)', link_or_id) or re.search(r'/d/([A-Za-z0-9_-]+)/', link_or_id)\n",
    "    if m:\n",
    "        file_id = m.group(1)\n",
    "    else:\n",
    "        # maybe the user passed only an id\n",
    "        file_id = link_or_id\n",
    "\n",
    "    out_zip = Path('custom_dataset.zip')\n",
    "    url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
    "    print('Downloading from', url)\n",
    "    gdown.download(url, str(out_zip), quiet=False)\n",
    "\n",
    "    # Extract\n",
    "    print('Extracting', out_zip)\n",
    "    with zipfile.ZipFile(out_zip, 'r') as zf:\n",
    "        # Extract into a temporary directory then move contents to target_dir\n",
    "        tmpdir = Path('tmp_dataset_extract')\n",
    "        if tmpdir.exists():\n",
    "            shutil.rmtree(tmpdir)\n",
    "        tmpdir.mkdir()\n",
    "        zf.extractall(tmpdir)\n",
    "\n",
    "        # Try to find audio/ and transcriptions/ inside extracted tree\n",
    "        candidates = [p for p in tmpdir.iterdir() if p.is_dir()]\n",
    "        if len(candidates) == 1:\n",
    "            root = candidates[0]\n",
    "        else:\n",
    "            root = tmpdir\n",
    "\n",
    "        # Move or copy audio/ and transcriptions/ into target_dir\n",
    "        for sub in ['audio', 'transcriptions']:\n",
    "            src = root / sub\n",
    "            if src.exists():\n",
    "                dest = target_dir / sub\n",
    "                if dest.exists():\n",
    "                    shutil.rmtree(dest)\n",
    "                shutil.move(str(src), str(dest))\n",
    "\n",
    "    print('Cleaning up temporary files')\n",
    "    out_zip.unlink(missing_ok=True)\n",
    "    shutil.rmtree('tmp_dataset_extract', ignore_errors=True)\n",
    "    print('Dataset prepared at', target_dir.resolve())\n",
    "    return target_dir.resolve()\n",
    "\n",
    "# Ask the user for a Google Drive link or file id. If you want to skip and use HF librispeech, just leave blank and press Enter.\n",
    "gdrive_link = input('Enter Google Drive file link or id to a ZIP dataset (press Enter to skip and use HF Librispeech): ').strip()\n",
    "custom_data_path = None\n",
    "if gdrive_link:\n",
    "    custom_data_path = download_and_unzip_gdrive(gdrive_link)\n",
    "    print('Custom dataset ready at:', custom_data_path)\n",
    "else:\n",
    "    print('Skipping custom dataset. Notebook will demonstrate HF Librispeech streaming if enabled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0bc9f",
   "metadata": {},
   "source": [
    "## 4) Run inference\n",
    "This cell runs `inference.py` with Hydra overrides. If you downloaded a custom dataset in the previous cell, the notebook will run inference using `datasets.custom_dir`. Otherwise it will run the HF Librispeech streaming evaluation (if enabled in config).\n",
    "The command below runs `inference.py` as a subprocess and prints stdout/stderr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def run_inference_on_custom(custom_path=None, output_dir='inference_predictions'):\n",
    "    cmd = ['python', 'inference.py']\n",
    "    if custom_path is not None:\n",
    "        # pass hydra overrides to enable custom_dir and set path\n",
    "        cmd += [f'datasets.custom_dir.enabled=True', f'datasets.custom_dir.path={custom_path}', f'inferencer.output_dir={output_dir}']\n",
    "    else:\n",
    "        print('No custom dataset provided. Running inference with default config (HF Librispeech if configured).')\n",
    "\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print('=== STDOUT ===')\n",
    "    print(proc.stdout)\n",
    "    print('=== STDERR ===')\n",
    "    print(proc.stderr)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f'Inference script failed with code {proc.returncode}')\n",
    "    return Path(output_dir).resolve()\n",
    "\n",
    "# Run inference depending on whether the user provided a custom dataset\n",
    "out_dir = None\n",
    "try:\n",
    "    if 'custom_data_path' in globals() and custom_data_path:\n",
    "        out_dir = run_inference_on_custom(str(custom_data_path))\n",
    "    else:\n",
    "        out_dir = run_inference_on_custom(None)\n",
    "    print('Inference finished. Predictions saved under:', out_dir)\n",
    "except Exception as e:\n",
    "    print('Inference failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af02697",
   "metadata": {},
   "source": [
    "## 5) Compute metrics (WER/CER)\n",
    "`evaluator.py` (the repo's metrics script) expects a folder with ground-truth `.txt` files and a folder with prediction `.txt` files. By default the config in `src/configs/metrics_eval.yaml` sets `paths.gt_dir` and `paths.pred_dir`.\n",
    "If your ground truth files are in `data/ground_truth` and predictions were written to e.g. `inference_predictions/custom/`, run the evaluator with hydra overrides to match those paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def run_evaluator(gt_dir, pred_dir, out_path='metrics/wer_cer_report.json'):\n",
    "    cmd = ['python', 'evaluator.py', f'paths.gt_dir={gt_dir}', f'paths.pred_dir={pred_dir}', f'out_path={out_path}']\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print('=== STDOUT ===')\n",
    "    print(proc.stdout)\n",
    "    print('=== STDERR ===')\n",
    "    print(proc.stderr)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f'Evaluator failed with code {proc.returncode}')\n",
    "    return Path(out_path).resolve()\n",
    "\n",
    "# Determine example gt_dir/pred_dir.\n",
    "# If you used a custom dataset that had transcriptions/, use that folder as gt_dir.\n",
    "if 'custom_data_path' in globals() and custom_data_path:\n",
    "    gt_dir = Path(custom_data_path) / 'transcriptions'\n",
    "    # Predictions structure depends on the inferencer output; often predictions will be in output_dir/<part>/pred_ID*.txt\n",
    "    # We assume predictions were saved to inference_predictions/custom/ or inference_predictions/<part>/\n",
    "    pred_dir = Path('inference_predictions')\n",
    "else:\n",
    "    # If you used HF Librispeech the predictions path must be set according to the inferencer output.\n",
    "    gt_dir = Path('data/ground_truth')\n",
    "    pred_dir = Path('data/predictions')\n",
    "\n",
    "print('GT dir:', gt_dir)\n",
    "print('Pred dir (top-level):', pred_dir)\n",
    "\n",
    "# Run evaluator if directories look valid\n",
    "if gt_dir.exists() and pred_dir.exists():\n",
    "    report = run_evaluator(str(gt_dir), str(pred_dir))\n",
    "    print('Saved metrics report to', report)\n",
    "else:\n",
    "    print('Ground-truth or prediction directory not found.\n",
    "Please set the correct paths:')\n",
    "    print('  - Ground truth (folder of .txt):', gt_dir)\n",
    "    print('  - Predictions (folder of .txt):', pred_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f0a07",
   "metadata": {},
   "source": [
    "## Notes and next steps\n",
    "- The notebook runs the existing `inference.py` and `evaluator.py` scripts via subprocess.\n",
    "- If `inference.py` or `evaluator.py` require additional config flags in your environment (GPU selection, different batch sizes), pass them using additional Hydra overrides in the command lists above. Example: `inferencer.device=cuda` or `inferencer.batch_size=8`.\n",
    "- I used `evaluator.py` present in the repository (named `evaluator.py`) rather than `calc_metrics.py` since there is no `calc_metrics.py` file. If you want a different evaluator script, adapt the evaluator-running cell accordingly.\n",
    "\n",
    "Outputs:\n",
    "- Checkpoints: `checkpoints/encoder.pth` and `checkpoints/decoder.pth`\n",
    "- Predictions: folder specified by `inferencer.output_dir` (default `inference_predictions`)\n",
    "- Metrics report: JSON at `metrics/wer_cer_report.json` (configurable via evaluator overrides)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
